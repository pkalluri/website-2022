<body>

	<head>
		<title>Pratyusha Ria Kalluri</title>
		<!-- <link rel="icon" href="/images/favicon.ico?" type="image/x-icon"> -->
		<!-- <link rel="shortcut icon" href="favicon.ico"> -->
		<link rel="icon" type="image/x-icon" href="myfavicon.ico"/>

		<link rel="stylesheet" href=style.css>
	</head>

	<div class="wrapper">
		<img style="padding:0 15; border-radius:50%; float:left;" src="images/h-s.jpg" height=150px >
		<div style="height:150px; display:flex; align-items:center;">
			<span>
				<h1>Pratyusha Ria Kalluri</h1>
				PhD student in the <a href="http://ai.stanford.edu">Stanford Artificial Intelligence Laboratory</a> <br>
			</span>
    	</div>

    	<section>
			<h1>Bio</h1>
			I am a second-year PhD student in computer science at the Stanford Artificial Intelligence Laboratory, where I am advised by <a href="https://cs.stanford.edu/~ermon/"  target="_blank">Stefano Ermon</a> in the <a href="http://statsml.stanford.edu"  target="_blank">Statistical Machine Learning Group</a> and <a href="http://web.stanford.edu/~jurafsky/"  target="_blank">Dan Jurafsky</a> in the <a href="https://nlp.stanford.edu/"  target="_blank">Natural Language Processing Group</a>.

			<!-- I am working on novel representation learning and learning objectives for deep generative models. I am working towards more reasonable, interpretable, and equitable machine learning.  -->

			<!-- this motivates novel representation learning and learning objectives for deep generative models. -->

			<!-- <span class="highlight">  </span> -->

			I am interested in finding and encouraging conceputal reasoning inside machine learning models. This leads me to work on novel learning objectives, learning disentangled representations,  and interpretability. For me, this work is related to envisioning more radical machine learning.
			<!-- I'm interested in designing and analyzing <i>representation learning</i> and <i>suitable learning objectives</i> that enable machine learning models in general and deep generative models in particular to reason better. 
			I'm interested in designing and analyzing <i>representation learning</i> and <i>suitable learning objectives</i> that enable machine learning models in general and deep generative models in particular to reason better.  -->

			<!-- I'm particularly interested in AI for fairness, accountability, and transparency, as well as equity and co-liberation. -->
			<!-- I'm deeply committed to disentangled, interpretable, and equitable machine learning. -->
			<br>
			<br>
			Previously, I interned at Microsoft (2014), and I completed my bachelors in computer science at MIT (2016), where my research advisor was Patrick Winston, whose advisor was Marvin Minsky. I was also a visiting researcher at University Complutense in Madrid (2017), advised by Pablo Gervas. At MIT and Complutense, I built models of human reasoning. This lineage continues to affect my view of where machine learning should be heading. 

<!-- 			Previously, I interned at Microsoft (2014), completed my bachelors in computer science at MIT (2016), and was a visiting researcher at University Complutense in Madrid (2017), where I built symbolic and probabilistic models of human  reasoning.
 -->			<br><br>I have received an <a href="https://www.nsfgrfp.org/"  target="_blank">NSF Graduate Research Fellowship</a>, the <a href="https://www.pdsoros.org/"  target="_blank">Paul and Daisy Soros Fellowship</a>, the <a href="https://vpge.stanford.edu/fellowships-funding/enhancing-diversity-graduate"  target="_blank">Stanford EDGE Fellowship</a>, the Stanford School of Engineering Fellowship, and the <a href="https://joininteract.com/"  target="_blank">Interact Fellowship</a>.
			I am also an artist, previously under the mentorship of <a href="http://www.junotdiaz.com/"  target="_blank">Junot D&iacute;az</a> and <a href="http://www.charifshanahan.com/"  target="_blank">Charif Shanahan.</a>
		</section>	

		<section id="news">
			<h1>News</h1>
			<ul>

			<!-- <li class="news">
			<span class="date">April '19</span>  
			<div class="event">I will be on a panel on how FATE (fair, accountable, transparent, and ethical) machine learning research affects the queer community
			</div>
			</li> -->

			<li class="news">
			<span class="date">April '19</span>  
			<div class="event">I wrote a <a href="https://ermongroup.github.io/blog/controllable-fairness/"  target="_blank">blogpost</a> about controllable fair machine learning
			</div>
			</li>

			<li class="news">
			<span class="date">April '19</span>  
			<div class="event">I am a recipient of the <a href="https://www.nsfgrfp.org/"  target="_blank">NSF Graduate Research Fellowship</a>
			</div>
			</li>

			<li class="news">
			<span class="date">Feb '19</span>  
			<div class="event">I am a finalist for the <a href="https://www.openphilanthropy.org/focus/global-catastrophic-risks/potential-risks-advanced-artificial-intelligence/open-philanthropy-project-ai-fellows-program"  target="_blank">Open Philanthropy Project AI Fellowship</a>; wish me luck!
			</div>
			</li>

			<li class="news">
			<span class="date">Feb '19</span>  
			<div class="event">I am co-leading Stanford's first Inclusion in AI group
			</div>
			</li>

			<li class="news">
			<span class="date">Jan '19</span> 
			<div class="event">I was a volunteer organizer at the <a href="https://fatconference.org/"  target="_blank">Fairness, Accountability, & Transparency*</a> in ML Conference<br>
			</div>
			</li>

			<li class="news">
			<span class="date">Dec '18</span>  
			<div class="event">My paper <a href="https://arxiv.org/abs/1812.04218"  target="_blank">Learning Controllable Fair Representations</a> was accepted to <a href="https://www.aistats.org/"  target="_blank">AISTATS</a></div>
			</li>

			<li class="news">
			<span class="date">Dec '18</span>  
			<div class="event">I gave the talk 
			"Fairness and Ethics in AI" at the Y Combinator AI Conference at OpenAI
			</div>
			</li>

			<li class="news">
			<span class="date">June '18</span> 
			<div class="event">
			Alvaro Bedoya & I gave the talk 
			"The Paradox of Privacy" at the PD Soros Fellowship 20th Reunion<br>
			</div>
			</li>

			<li class="news">
			<span class="date">Sept '17</span> 
			<div class="event">I began my PhD in computer science at Stanford
			</div>
			</li>

			</ul>
		</section>

		<section>
			<h1>Blog posts</h1>
			<ul>
			<li>
			<a href="https://ermongroup.github.io/blog/controllable-fairness/"  target="_blank">Controllable Fair Machine Learning</a><br>
			Pratyusha Kalluri<br>
			Ermon Group blog<br>
			</li>
			</ul>
		</section>

		<section>
			<h1>Papers</h1>
			<ul>
			<li>
			<a href="aistats19.pdf"  target="_blank">Learning Controllable Fair Representations</a><br>
			Jiaming Song*, Pratyusha Kalluri*, Aditya Grover, Shengjia Zhao, Stefano Ermon <br>
			*equal authorship <br>
			International Conference on Artificial Intelligence and Statistics (AISTATS), 2019.<br>
			</li>

			<li>
			<a href="http://www.cogsys.org/papers/ACSvol6/posters/Kalluri.pdf"  target="_blank">Inducing Schizophrenia in an Artificially Intelligent Story-Understanding System</a><br>
			Pratyusha Kalluri, Patrick H. Winston<br>
			Conference on Advances in Cognitive Systems (ACS), 2018.<br>
			</li>

			<li>
			<a href="https://www.scitepress.org/papers/2017/62055/pdf/index.html"  target="_blank">Relationship Affinity-based Interpretation of Triangle Social Scenarios</a><br>
			Pratyusha Kalluri, Pablo Gervas<br>
			International Conference on Agents and Artificial Intelligence (ICAART), 2017.<br>
			</li>

			<li><h2>Workshop papers</h2></li>

			<li>
			<a href="aistats19.pdf"  target="_blank">Learning Controllable Fair Representations via Latent Variable Generative Models</a><br>
			Jiaming Song, Pratyusha Kalluri, Aditya Grover, Shengjia Zhao, Stefano Ermon <br>
			ICML Workshop on Theoretical Foundations and Applications of Deep Generative Models, 2018.<br>
			</li>
			</ul>
		</section>

		<!-- <section>
			<h1>Workshop papers</h1>
			<ul>
			<li>
			<a href="https://arxiv.org/abs/1812.04218 ">Learning Controllable Fair Representations via Latent Variable Generative Models</a><br>
			Jiaming Song, Pratyusha Kalluri, Aditya Grover, Shengjia Zhao, Stefano Ermon <br>
			ICML Workshop on Theoretical Foundations and Applications of Deep Generative Models, 2018.<br>
			</li>
			</ul>
		</section> -->

		<section>
			<h1>Talks</h1>
			<ul>
			<li>
			<b>Fairness and Ethics in AI</b><br>
			Pratyusha Kalluri<br>
			Y Combinator AI Conference at OpenAI, Session, 2018.<br>
			</li>

			<li>
			<b>The Paradox of Privacy: Marginalized communities have long borne the brunt of "ubiquitous" surveillance</b><br>
			Pratyusha Kalluri, Alvaro Bedoya<br>
			Paul & Daisy Soros Fellowship 20th Reunion at the Broadmoor Hotel, Session, 2018.<br>
			</li>
			</ul>
		</section>

<!-- 		<section>
			<span class="highlight">I am also a writer, previously under the mentorship of Junot D&iacute;az and Charif Shanahan.</span>
		</section> -->


<!-- 		<section>
			Why pink? Where I am in the world, pink is often perceived as feminine, soft, and childish and not as smart, technical, and mathy. Writing in pink reminds me to not bother trying to signify my mathiness — it's a losing battle. Writing in pink reminds me to just do the math, enjoy the math, publish the math.
		</section> -->

		<section style="text-align: center;">pkalluri@stanford.edu</section>







	</div>
</body>